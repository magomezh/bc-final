{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('Ireviews.csv')\n",
    "#Keeping only the neccessary columns\n",
    "data = data[['Review','Sentiment']]\n",
    "data.Review=data.Review.astype(str)\n",
    "data.Sentiment=data.Sentiment.astype(str)\n",
    "\n",
    "#data = pd.read_csv('Sentiment.csv')\n",
    "#data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522\n",
      "4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "data = data[data.Sentiment != \"Neutral\"]\n",
    "data['Review'] = data['Review'].apply(lambda x: x.lower())\n",
    "data['Review'] = data['Review'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['Sentiment'] == 'POSITIVE'].size)\n",
    "print(data[ data['Sentiment'] == 'NEGATIVE'].size)\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['Review'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Review'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.sentiment != \"Neutral\"]\n",
    "# data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "# print(data[ data['sentiment'] == 'Positive'].size)\n",
    "# print(data[ data['sentiment'] == 'Negative'].size)\n",
    "\n",
    "# for idx,row in data.iterrows():\n",
    "#     row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "# max_fatures = 2000\n",
    "# tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "# tokenizer.fit_on_texts(data['text'].values)\n",
    "# X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "# X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.sentiment != \"Neutral\"]\n",
    "# data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "# print(data[ data['sentiment'] == 'Positive'].size)\n",
    "# print(data[ data['sentiment'] == 'Negative'].size)\n",
    "\n",
    "# for idx,row in data.iterrows():\n",
    "#     row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "# max_fatures = 2000\n",
    "# tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "# tokenizer.fit_on_texts(data['text'].values)\n",
    "# X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "# X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\ni have many equipment from apple i would say...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nwere a family of apple products just like th...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nordered a mac mini that when hooked to my sa...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nso me and my family turned from samsung to a...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nthank you for helping me fix my iphone i con...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nnice phone but the battery drains fast might...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\ni have never been a fan of apple but when i ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nin the uk recently bought a new imac for dev...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nthey got my phone fast and great condition n...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nthis review is specifically for their online...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\njust got a refurbished macbook pro and its t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\njust got a refurbished macbook pro and its t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\njust got a refurbished macbook pro and its t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>thanks for your help fixing my ipad pro cause ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\napple its how a computer should be built  ps...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nlong time apple customer they always deliver...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\nlove apple products and items\\n</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\ni want to give the best acknowledgement to c...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\ni am using iphone 11 pro max and i am loving...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\nexcellent buying experience as always good r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\ngreat customer service from josh amp helped ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\ni am using iphone 11 pro max and i am loving...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nexcellent buying experience as always good r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\ngreat customer service from josh amp helped ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\ni love apple and its products are just aweso...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\ni love apple and its products are just aweso...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\nalways very high quality and professional pr...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nan</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nan</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\nkyle helped me on apple support and he was s...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\nwell january 17 my lockout i had got so use ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n                dual boiler machine is fabul...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\n                my experience with support w...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n                amazing customer service the...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\n                dual boiler machine is fabul...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\n                my experience with support w...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\n                amazing customer service the...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n                i sincerely dont know what w...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n                my boss breville blender was...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\n                bought breville hot water di...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review Sentiment\n",
       "0   \\ni have many equipment from apple i would say...  POSITIVE\n",
       "1   \\nwere a family of apple products just like th...  POSITIVE\n",
       "2   \\nordered a mac mini that when hooked to my sa...  POSITIVE\n",
       "3   \\nso me and my family turned from samsung to a...  POSITIVE\n",
       "4   \\nthank you for helping me fix my iphone i con...  POSITIVE\n",
       "5   \\nnice phone but the battery drains fast might...  POSITIVE\n",
       "6   \\ni have never been a fan of apple but when i ...  POSITIVE\n",
       "7   \\nin the uk recently bought a new imac for dev...  POSITIVE\n",
       "8   \\nthey got my phone fast and great condition n...  POSITIVE\n",
       "9   \\nthis review is specifically for their online...  POSITIVE\n",
       "10  \\njust got a refurbished macbook pro and its t...  POSITIVE\n",
       "11  \\njust got a refurbished macbook pro and its t...  POSITIVE\n",
       "12  \\njust got a refurbished macbook pro and its t...  POSITIVE\n",
       "13  thanks for your help fixing my ipad pro cause ...  POSITIVE\n",
       "14  \\napple its how a computer should be built  ps...  POSITIVE\n",
       "15  \\nlong time apple customer they always deliver...  POSITIVE\n",
       "16      \\nlove apple products and items\\n              POSITIVE\n",
       "17  \\ni want to give the best acknowledgement to c...  POSITIVE\n",
       "18  \\ni am using iphone 11 pro max and i am loving...  POSITIVE\n",
       "19  \\nexcellent buying experience as always good r...  POSITIVE\n",
       "20  \\ngreat customer service from josh amp helped ...  POSITIVE\n",
       "21  \\ni am using iphone 11 pro max and i am loving...  POSITIVE\n",
       "22  \\nexcellent buying experience as always good r...  POSITIVE\n",
       "23  \\ngreat customer service from josh amp helped ...  POSITIVE\n",
       "24  \\ni love apple and its products are just aweso...  POSITIVE\n",
       "25  \\ni love apple and its products are just aweso...  POSITIVE\n",
       "26  \\nalways very high quality and professional pr...  POSITIVE\n",
       "27                                                nan  POSITIVE\n",
       "28                                                nan  POSITIVE\n",
       "29  \\nkyle helped me on apple support and he was s...  POSITIVE\n",
       "30  \\nwell january 17 my lockout i had got so use ...  POSITIVE\n",
       "31  \\n                dual boiler machine is fabul...  POSITIVE\n",
       "32  \\n                my experience with support w...  POSITIVE\n",
       "33  \\n                amazing customer service the...  POSITIVE\n",
       "34  \\n                dual boiler machine is fabul...  POSITIVE\n",
       "35  \\n                my experience with support w...  POSITIVE\n",
       "36  \\n                amazing customer service the...  POSITIVE\n",
       "37  \\n                i sincerely dont know what w...  POSITIVE\n",
       "38  \\n                my boss breville blender was...  POSITIVE\n",
       "39  \\n                bought breville hot water di...  POSITIVE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       object\n",
       "Sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(196, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 838, 128)          256000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "keras.layers.SpatialDropout1D\n",
    "model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1628, 838) (1628, 2)\n",
      "(803, 838) (803, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['Sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 161s - loss: 0.2619 - accuracy: 0.9097\n",
      "Epoch 2/3\n",
      " - 332s - loss: 0.1225 - accuracy: 0.9588\n",
      "Epoch 3/3\n",
      " - 409s - loss: 0.0715 - accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a408588688>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "model.fit(X_train, Y_train, nb_epoch = 3, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.12\n",
      "acc: 0.95\n"
     ]
    }
   ],
   "source": [
    "validation_size = 400\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2 , batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 82.6086956521739 %\n",
      "neg_acc 98.58757062146893 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
